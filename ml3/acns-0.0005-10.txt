D:\Anaconda3\python.exe D:/PycharmProjects/untitled5/ACN-simple.py
cuda:0
Files already downloaded and verified
Files already downloaded and verified
Net(
  (conv1): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv4): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv5): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (conv7): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1))
  (conv8): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
  (conv9): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))
  (global_avg_pool): AvgPool2d(kernel_size=6, stride=6, padding=0)
  (drop1): Dropout2d(p=0.5)
  (drop2): Dropout2d(p=0.5)
)
[1,    20] loss: 2.2340170741 time: 12.017
[1,    40] loss: 2.1163156867 time: 15.344
[1,    60] loss: 2.0473591208 time: 18.674
[1,    80] loss: 1.9580434918 time: 22.027
[1,   100] loss: 1.9028057873 time: 25.370
[1,   120] loss: 1.8673500419 time: 28.713
[1,   140] loss: 1.8425624311 time: 32.037
[1,   160] loss: 1.8076891780 time: 35.378
[1,   180] loss: 1.7826125145 time: 38.709
[2,    20] loss: 1.7345069528 time: 48.047
[2,    40] loss: 1.7280154347 time: 51.387
[2,    60] loss: 1.6614694059 time: 54.737
[2,    80] loss: 1.6757356882 time: 58.100
[2,   100] loss: 1.6434612155 time: 61.458
[2,   120] loss: 1.6122332990 time: 64.821
[2,   140] loss: 1.6164952397 time: 68.193
[2,   160] loss: 1.5858145177 time: 71.569
[2,   180] loss: 1.5592810392 time: 74.978
[3,    20] loss: 1.5903858840 time: 84.678
[3,    40] loss: 1.5419557154 time: 88.009
[3,    60] loss: 1.5105620742 time: 91.344
[3,    80] loss: 1.5113297224 time: 94.679
[3,   100] loss: 1.4991176605 time: 98.021
[3,   120] loss: 1.4942477226 time: 101.346
[3,   140] loss: 1.4567381144 time: 104.665
[3,   160] loss: 1.4336913466 time: 108.004
[3,   180] loss: 1.4346584857 time: 111.351
[4,    20] loss: 1.4155797780 time: 120.690
[4,    40] loss: 1.3480796158 time: 124.014
[4,    60] loss: 1.3387404561 time: 127.332
[4,    80] loss: 1.3910103023 time: 130.672
[4,   100] loss: 1.3647472322 time: 134.001
[4,   120] loss: 1.3394708395 time: 137.335
[4,   140] loss: 1.2834334314 time: 140.665
[4,   160] loss: 1.3081961393 time: 144.008
[4,   180] loss: 1.2955265582 time: 147.351
[5,    20] loss: 1.2982007146 time: 156.655
[5,    40] loss: 1.2490484059 time: 160.002
[5,    60] loss: 1.2196333528 time: 163.335
[5,    80] loss: 1.2248959780 time: 166.672
[5,   100] loss: 1.2163579822 time: 170.002
[5,   120] loss: 1.1893398821 time: 173.362
[5,   140] loss: 1.2130750477 time: 176.713
[5,   160] loss: 1.2047966778 time: 180.075
[5,   180] loss: 1.2218759716 time: 183.415
[6,    20] loss: 1.1560157716 time: 192.812
[6,    40] loss: 1.1841605783 time: 196.176
[6,    60] loss: 1.1644250631 time: 199.523
[6,    80] loss: 1.1278704464 time: 202.853
[6,   100] loss: 1.1620673537 time: 206.182
[6,   120] loss: 1.0739311874 time: 209.541
[6,   140] loss: 1.1076314628 time: 212.882
[6,   160] loss: 1.1189486623 time: 216.214
[6,   180] loss: 1.1059374362 time: 219.574
[7,    20] loss: 1.0691259325 time: 228.938
[7,    40] loss: 1.1138512552 time: 232.278
[7,    60] loss: 1.0839027822 time: 235.599
[7,    80] loss: 1.0528184950 time: 238.945
[7,   100] loss: 1.0313368201 time: 242.284
[7,   120] loss: 1.0668719620 time: 245.603
[7,   140] loss: 1.0441909015 time: 248.954
[7,   160] loss: 1.0181274176 time: 252.318
[7,   180] loss: 1.0181809336 time: 255.688
[8,    20] loss: 1.0371236235 time: 265.538
[8,    40] loss: 1.0229487836 time: 268.880
[8,    60] loss: 0.9671311826 time: 272.198
[8,    80] loss: 0.9986090600 time: 275.534
[8,   100] loss: 1.0129710317 time: 278.876
[8,   120] loss: 0.9882146418 time: 282.215
[8,   140] loss: 1.0111906946 time: 285.534
[8,   160] loss: 0.9685206294 time: 288.881
[8,   180] loss: 0.9675809443 time: 292.228
[9,    20] loss: 0.9500024736 time: 301.620
[9,    40] loss: 0.9426674545 time: 304.954
[9,    60] loss: 0.9375201285 time: 308.307
[9,    80] loss: 0.9162470281 time: 311.676
[9,   100] loss: 0.9586152822 time: 315.020
[9,   120] loss: 0.9502798617 time: 318.374
[9,   140] loss: 0.9523376375 time: 321.725
[9,   160] loss: 0.9489055693 time: 325.064
[9,   180] loss: 0.9317218870 time: 328.411
[10,    20] loss: 0.9094275117 time: 337.811
[10,    40] loss: 0.8841644704 time: 341.155
[10,    60] loss: 0.9155643940 time: 344.482
[10,    80] loss: 0.9128945917 time: 347.847
[10,   100] loss: 0.9131603897 time: 351.186
[10,   120] loss: 0.8904262602 time: 354.526
[10,   140] loss: 0.8744222760 time: 357.875
[10,   160] loss: 0.9071430117 time: 361.187
[10,   180] loss: 0.8888790965 time: 364.528
Finished Training
Accuracy of the network on the 10000 test images: 67 %
Accuracy of plane : 50 %
Accuracy of   car : 84 %
Accuracy of  bird : 76 %
Accuracy of   cat : 68 %
Accuracy of  deer : 30 %
Accuracy of   dog : 40 %
Accuracy of  frog : 55 %
Accuracy of horse : 58 %
Accuracy of  ship : 85 %
Accuracy of truck : 64 %

Process finished with exit code 0
